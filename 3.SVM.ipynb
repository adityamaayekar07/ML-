import numpy as np
import matplotlib.pyplot as plt
from sklearn.svm import SVC
from sklearn.datasets import make_blobs

# Generate synthetic data
X, y = make_blobs(n_samples=100, centers=2, random_state
                  =6, cluster_std=1.5)

# Fit the SVM model
svm = SVC(kernel='linear', C=1)
svm.fit(X, y)

# Get the separating hyperplane
w = svm.coef_[0]
b = svm.intercept_[0]

# Calculate slope and intercept for the hyperplane
x0 = np.linspace(min(X[:, 0]), max(X[:, 0]), 100)
x1 = -(w[0] / w[1]) * x0 - b / w[1]

# Plot the data points and the hyperplane
plt.scatter(X[:, 0], X[:, 1], c=y, cmap='coolwarm', s=50)
plt.plot(x0, x1, 'k-', label='Hyperplane')

# Plot the support vectors
plt.scatter(svm.support_vectors_[:, 0], svm.support_vectors_[:, 1],
            facecolors='none', edgecolors='k', s=100, label='Support Vectors')

plt.title("SVM Classification with Hyperplane")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.legend()
plt.grid(True)
plt.show()


-----code 2 decison boundary------

import numpy as np
import matplotlib.pyplot as plt
from sklearn.svm import SVC
from sklearn.datasets import make_classification

# Generate synthetic data
X, y = make_classification(
    n_features=2, n_classes=2, n_informative=2, n_redundant=0, random_state=42
)

# Train a linear SVM
svm = SVC(kernel='linear')
svm.fit(X, y)

# Extract coefficients and intercept
w = svm.coef_[0]
b = svm.intercept_[0]

# Define decision boundary
x0 = np.linspace(min(X[:, 0]), max(X[:, 0]), 100)
x1 = -(w[0] / w[1]) * x0 - b / w[1]

# Plot data points
plt.scatter(X[:, 0], X[:, 1], c=y, cmap='coolwarm', s=50, edgecolor='k')

# Plot decision boundary
plt.plot(x0, x1, 'k-', label='Hyperplane')

# Add labels and legend
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.title("SVM Decision Boundary")
plt.legend()
plt.show()
